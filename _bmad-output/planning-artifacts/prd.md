# Product Requirements Document (PRD)
## TestFlowKit - Enterprise Edition

**Version:** 1.0  
**Date:** 2026-01-22  
**Auteur:** Product Manager (John)  
**Statut:** Draft - Ready for Review  
**Type de projet:** Brownfield Enhancement

---

## üìã Executive Summary

### Vision Produit
Transformer TestFlowKit d'un framework de test automation open-source performant en **la solution enterprise de r√©f√©rence pour le test automation BDD**, combinant simplicit√© Gherkin, performance Go, et capacit√©s enterprise-grade.

### Objectif Strat√©gique
Positionner TestFlowKit comme concurrent s√©rieux de Cypress, Playwright et Selenium Grid pour les √©quipes enterprise recherchant:
- ‚úÖ **Performance sup√©rieure** (Go natif)
- ‚úÖ **Simplicit√© BDD** (Gherkin accessible √† tous)
- ‚úÖ **Multi-canal** (Frontend + Backend + GraphQL)
- ‚úÖ **Enterprise-ready** (s√©curit√©, compliance, scalabilit√©)

### Opportunity Statement
Le march√© du test automation est domin√© par des solutions JavaScript/Python complexes ou des outils propri√©taires co√ªteux. **TestFlowKit** peut capturer une part significative en offrant:
- Performance Go (5-10x plus rapide que JavaScript)
- BDD natif (collaboration Product/QA/Dev)
- Open-source avec support enterprise
- ROI rapide (setup en minutes, r√©sultats imm√©diats)

### Target Release
**V1.0 Enterprise Edition:** Q2 2026 (7 semaines de d√©veloppement)

---

## üéØ Product Goals & Success Metrics

### Business Goals

1. **Market Penetration**
   - Atteindre 10,000 installations actives en 12 mois
   - Convertir 5% en utilisateurs enterprise (500 comptes)
   - G√©n√©ration de 100 success stories

2. **Revenue (si mod√®le commercial)**
   - Support enterprise: $5K-$50K/an par entreprise
   - Cloud hosting option: $500-$5K/mois
   - Training & certification: $2K-$10K

3. **Community Growth**
   - 5,000+ GitHub stars
   - 500+ contributors
   - 100+ plugins community

### User Goals

1. **QA Engineers**
   - R√©duire temps cr√©ation tests de 70%
   - Augmenter couverture tests de 40%
   - √âliminer 80% des tests flaky

2. **Developers**
   - Int√©gration CI/CD en < 30 minutes
   - Feedback tests en < 5 minutes
   - Debug facilit√© (logs, vid√©os, screenshots)

3. **Product Managers**
   - Specs ex√©cutables (Gherkin = documentation)
   - Visibilit√© temps r√©el qualit√© produit
   - Collaboration √©quipe am√©lior√©e

### Success Metrics

#### Adoption Metrics
- **Installation Rate:** 1,000+ downloads/mois
- **Activation Rate:** 60% utilisateurs lancent premier test < 1h
- **Retention Rate:** 40% utilisateurs actifs apr√®s 30 jours
- **Churn Rate:** < 10% mensuel

#### Performance Metrics
- **Test Execution Speed:** 5x plus rapide que Selenium
- **Setup Time:** < 10 minutes (vs 2-4h concurrents)
- **Test Stability:** < 2% flaky tests (vs 15-20% industrie)

#### Quality Metrics
- **Bug Detection Rate:** +50% vs tests manuels
- **Code Coverage:** 80%+ avec tests automatis√©s
- **False Positives:** < 1%

---

## üìä Current State Analysis

### Strengths (Points Forts Actuels)

#### Technical Excellence
‚úÖ **Architecture Clean** - 4 couches bien s√©par√©es  
‚úÖ **Performance Go** - Concurrency native, binaire standalone  
‚úÖ **Multi-Channel Testing** - Frontend + Backend + GraphQL  
‚úÖ **BDD Native** - Gherkin avec Godog  
‚úÖ **Smart Element Detection** - Multi-selector avec fallback  
‚úÖ **XPath Support** - Support complet XPath 1.0  
‚úÖ **Macro System** - R√©utilisation sc√©narios  
‚úÖ **Parallel Execution** - Tests concurrents  

#### User Experience
‚úÖ **Setup Rapide** - `tkit init` ‚Üí tests en 5 min  
‚úÖ **Config YAML** - Configuration lisible et flexible  
‚úÖ **HTML Reports** - Rapports interactifs avec screenshots  
‚úÖ **Auto Browser Init** - Initialisation automatique navigateur  

### Weaknesses (Lacunes Identifi√©es)

#### Enterprise Gaps (42 features manquantes)

**Security & Compliance (5)**
- ‚ùå Pas d'authentification/autorisation
- ‚ùå Pas de gestion secrets
- ‚ùå Pas de RBAC
- ‚ùå Pas d'audit logging
- ‚ùå Pas d'anonymisation donn√©es

**Reporting & Observability (5)**
- ‚ùå Pas de JUnit XML
- ‚ùå Pas d'historique/trends
- ‚ùå Pas de dashboard m√©triques
- ‚ùå Pas de distributed tracing
- ‚ùå Pas de monitoring temps r√©el

**Resilience & Reliability (4)**
- ‚ùå Pas de retry automatique
- ‚ùå Pas de test impact analysis
- ‚ùå Pas de circuit breaker
- ‚ùå D√©gradation gracieuse limit√©e

**Testing Capabilities (8)**
- ‚ùå Pas de video recording
- ‚ùå Pas de service virtualization
- ‚ùå Chrome uniquement (pas Firefox/Safari)
- ‚ùå Pas de mobile testing
- ‚ùå Pas de visual regression
- ‚ùå Pas de tests accessibilit√©
- ‚ùå Pas de performance testing
- ‚ùå Pas de database testing

**Developer Experience (6)**
- ‚ùå Pas de hooks scenario-level
- ‚ùå Plugin system limit√©
- ‚ùå Pas d'AI test generation
- ‚ùå Pas de test data management
- ‚ùå Pas de debug interactif
- ‚ùå Pas de test versioning

**Enterprise Infrastructure (5)**
- ‚ùå Ex√©cution distribu√©e limit√©e
- ‚ùå Pas d'int√©gration cloud (BrowserStack, etc.)
- ‚ùå Orchestration containers basique
- ‚ùå Pas de provisioning auto
- ‚ùå Pas de multi-tenancy

**Collaboration (4)**
- ‚ùå Pas de notifications (Slack/Teams)
- ‚ùå Pas de partage rapports
- ‚ùå Pas de collaboration √©quipe
- ‚ùå Pas d'int√©gration Jira/GitHub Issues

**Advanced Features (5)**
- ‚ùå Pas de chaos engineering
- ‚ùå Pas de A/B testing
- ‚ùå Pas de multi-langue rapports
- ‚ùå Pas de scheduling
- ‚ùå Pas de license management

### Opportunities

1. **Market Gap:** Pas de framework BDD Go enterprise-ready
2. **Performance Edge:** Go 5-10x plus rapide que JS/Python
3. **Developer Experience:** Simplifier setup et debug
4. **GraphQL Leadership:** Meilleur support GraphQL du march√©
5. **Cloud Native:** Parfait pour Kubernetes/containers

### Threats

1. **Cypress/Playwright** - Dominance march√©, √©cosyst√®me mature
2. **Learning Curve Go** - Moins d√©veloppeurs Go vs JS/Python
3. **Rod Limitation** - Chrome uniquement (d√©pendance externe)
4. **Community Size** - Communaut√© Go test plus petite
5. **Enterprise Inertia** - R√©sistance changement outils √©tablis

---

## üë• Target Market & User Personas

### Primary Market Segments

#### 1. Enterprise Software Companies
**Size:** 500-10,000+ employ√©s  
**Pain Points:**
- Tests Selenium lents et flaky
- Co√ªts licences Selenium Grid √©lev√©s
- Complexit√© setup et maintenance
- Manque collaboration Product/QA/Dev

**Value Proposition:**
- Performance 5x sup√©rieure
- Setup en minutes vs jours
- BDD pour collaboration
- Open-source + support enterprise

#### 2. SaaS Startups (Series A-C)
**Size:** 50-500 employ√©s  
**Pain Points:**
- Ressources QA limit√©es
- CI/CD pipeline lent
- Scaling tests difficile
- Budget limit√©

**Value Proposition:**
- Setup rapide (< 1h)
- Co√ªt r√©duit (open-source)
- Scaling horizontal facile
- Performance cloud-native

#### 3. Digital Agencies
**Size:** 20-200 employ√©s  
**Pain Points:**
- Projets clients multiples
- Environnements vari√©s
- Tests r√©gression co√ªteux
- Turnover √©quipe

**Value Proposition:**
- Multi-environment natif
- BDD = documentation client
- R√©utilisation tests (macros)
- Formation rapide (Gherkin)

### User Personas

#### Persona 1: Emma - Senior QA Engineer
**Background:**
- 8 ans exp√©rience QA automation
- Expert Selenium/Cypress
- Frustr√©e par tests flaky
- Recherche solution performante

**Goals:**
- R√©duire temps ex√©cution tests 70%
- √âliminer tests flaky
- Am√©liorer couverture tests
- Simplifier maintenance

**Pain Points:**
- Selenium trop lent (30 min ‚Üí 5 min)
- Tests flaky (20% √©chec non-d√©terministe)
- Setup complexe (2-3 jours)
- Debug difficile

**How TestFlowKit Helps:**
- Performance Go native
- Smart element detection
- Setup en 10 minutes
- Reports d√©taill√©s + screenshots

#### Persona 2: Marc - Full-Stack Developer
**Background:**
- 5 ans exp√©rience dev
- √âcrit tests d'int√©gration
- Utilise TDD/BDD
- Focus v√©locit√©

**Goals:**
- Tests rapides en CI/CD
- Feedback imm√©diat
- Tests lisibles (specs ex√©cutables)
- Minimal maintenance

**Pain Points:**
- CI/CD pipeline lent (15 min)
- Tests cassent souvent
- Config complexe
- Apprendre nouveau framework

**How TestFlowKit Helps:**
- Ex√©cution parall√®le native
- Auto-retry flaky tests
- Config YAML simple
- Gherkin = specs lisibles

#### Persona 3: Sophie - Product Manager
**Background:**
- 6 ans PM
- Responsable roadmap produit
- Collaborate avec Dev/QA
- Focus qualit√© et v√©locit√©

**Goals:**
- Specs ex√©cutables
- Visibilit√© qualit√© temps r√©el
- Collaboration √©quipe
- R√©duire bugs production

**Pain Points:**
- Disconnect specs ‚Üí tests
- Pas visibilit√© qualit√©
- Communication Dev/QA/PM difficile
- Bugs √©chappent aux tests

**How TestFlowKit Helps:**
- Gherkin = specs + tests
- Reports executive-friendly
- Collaboration BDD native
- Couverture tests visible

---

## üöÄ Feature Requirements

### Scope V1.0 Enterprise Edition

**Total Features:** 72 fonctionnalit√©s
- **Fonctionnalit√©s existantes:** 10 modules
- **Quick Wins (Priorit√© 1-2):** 20 features (Ready for V1)
- **Diff√©renciateurs (Priorit√© 3):** 10 features (V1 optional)
- **Enterprise Long-term:** 42 features (V2-V3 roadmap)

---

## üì¶ Feature Catalog

### üéØ PHASE 1: Must-Have Features (Sprint 1-2, 4 semaines)

#### FR-001: Allure Reporting Integration
**Priority:** P0 - Critical  
**Effort:** Faible (2-3 jours)  
**Impact:** Tr√®s √©lev√©  

**User Story:**
En tant que QA Engineer, je veux g√©n√©rer des rapports Allure pour avoir une visualisation professionnelle avec historique et trends.

**Acceptance Criteria:**
- [ ] AC1: Support format Allure JSON
- [ ] AC2: G√©n√©ration rapports Allure via `--report-format=allure`
- [ ] AC3: Historique tests (comparaison runs)
- [ ] AC4: Cat√©gorisation par features/severit√©
- [ ] AC5: Screenshots int√©gr√©s dans Allure
- [ ] AC6: Trends et m√©triques historiques
- [ ] AC7: Documentation Allure setup

**Technical Notes:**
- Library: `github.com/allure-framework/allure-go`
- R√©utiliser Reporter interface existant
- Ajouter AllureFormatter implements formatter

**Dependencies:** Aucune

**Success Metrics:**
- Rapports Allure g√©n√©r√©s en < 2s
- Compatibilit√© Allure 2.x
- 95%+ utilisateurs satisfaits reporting

---

#### FR-002: Cucumber JSON Export
**Priority:** P0 - Critical  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** √âlev√©  

**User Story:**
En tant que DevOps Engineer, je veux exporter r√©sultats en format Cucumber JSON pour int√©gration CI/CD (Jenkins, GitLab).

**Acceptance Criteria:**
- [ ] AC1: Format Cucumber JSON standard
- [ ] AC2: CLI flag `--report-format=cucumber-json`
- [ ] AC3: Compatibilit√© plugins Jenkins/GitLab
- [ ] AC4: Support tags et features metadata
- [ ] AC5: Timestamps pr√©cis
- [ ] AC6: Status mappings corrects

**Technical Notes:**
- R√©utiliser JSON reporter existant
- Mapper vers sch√©ma Cucumber JSON
- Fichier output: `cucumber-report.json`

**Dependencies:** Aucune

**Success Metrics:**
- 100% compatibilit√© plugins CI/CD
- Validation sch√©ma Cucumber

---

#### FR-003: Environment Variables CLI Override
**Priority:** P0 - Critical  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux override variables d'environnement via CLI pour tester diff√©rents environnements sans modifier config.

**Acceptance Criteria:**
- [ ] AC1: Syntaxe `--env KEY=VALUE`
- [ ] AC2: Multiple vars: `--env KEY1=VAL1 --env KEY2=VAL2`
- [ ] AC3: Override config.yaml env vars
- [ ] AC4: Support dans Gherkin `{{ env.KEY }}`
- [ ] AC5: Validation vars requises
- [ ] AC6: Documentation usage

**Technical Notes:**
- √âtendre CLI args parser existant
- Merge avec env vars config.yaml
- Priorit√©: CLI > .env file > config.yaml

**Dependencies:** Aucune

**Success Metrics:**
- Override fonctionne 100% cas
- Documentation claire

---

#### FR-004: Test Data Faker/Generator
**Priority:** P0 - Critical  
**Effort:** Faible (2 jours)  
**Impact:** √âlev√©  

**User Story:**
En tant que QA Engineer, je veux g√©n√©rer donn√©es de test al√©atoires (emails, noms, phones) pour √©viter hardcoding et am√©liorer robustesse.

**Acceptance Criteria:**
- [ ] AC1: Steps faker: `I set "field" to random email`
- [ ] AC2: Support types: email, name, phone, address, UUID, date
- [ ] AC3: Format custom: `random phone US format`
- [ ] AC4: Seed reproductible pour debug
- [ ] AC5: Int√©gration variable system
- [ ] AC6: Documentation step library

**Technical Notes:**
- Library: `github.com/brianvoe/gofakeit`
- Nouveaux steps dans `variables/faker.go`
- Storage dans context variables

**Dependencies:** Variable system existant

**Success Metrics:**
- 20+ types donn√©es support√©s
- Tests reproductibles avec seed

---

#### FR-005: Basic Performance Metrics
**Priority:** P0 - Critical  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux capturer m√©triques performance (temps r√©ponse API, page load) dans rapports.

**Acceptance Criteria:**
- [ ] AC1: Temps r√©ponse API dans logs
- [ ] AC2: Page load time dans rapports
- [ ] AC3: Step execution time d√©taill√©
- [ ] AC4: M√©triques agr√©g√©es par scenario
- [ ] AC5: Warnings si > threshold
- [ ] AC6: Export m√©triques CSV/JSON

**Technical Notes:**
- R√©utiliser timers existants
- Ajouter Performance struct dans Report
- Capturer dans AfterStep hook

**Dependencies:** Reporter existant

**Success Metrics:**
- M√©triques pr√©cises (¬±10ms)
- Overhead < 1% temps ex√©cution

---

#### FR-006: CSV/Excel Data-Driven Testing
**Priority:** P1 - High  
**Effort:** Faible (2-3 jours)  
**Impact:** √âlev√©  

**User Story:**
En tant que QA Engineer, je veux ex√©cuter Scenario Outline avec donn√©es CSV pour tester multiples cas sans dupliquer code.

**Acceptance Criteria:**
- [ ] AC1: Syntaxe: `Examples: @data(users.csv)`
- [ ] AC2: Support CSV avec headers
- [ ] AC3: Support Excel (.xlsx)
- [ ] AC4: Mapping colonnes ‚Üí variables
- [ ] AC5: Skip rows invalides avec warning
- [ ] AC6: Rapports montrent data source
- [ ] AC7: Documentation + exemples

**Technical Notes:**
- Library: `encoding/csv` (stdlib)
- Excel: `github.com/xuri/excelize`
- Parser custom pour Examples tag
- Int√©gration Godog Scenario Outline

**Dependencies:** Macro system, variable system

**Success Metrics:**
- Support 10,000+ rows CSV
- Performance loading < 1s

---

#### FR-007: Console Logs Capture
**Priority:** P1 - High  
**Effort:** Faible (1-2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux voir console logs browser dans rapports pour debug erreurs JavaScript.

**Acceptance Criteria:**
- [ ] AC1: Capture console.log, .warn, .error
- [ ] AC2: Affichage dans HTML report
- [ ] AC3: Filtrage par level (log/warn/error)
- [ ] AC4: Timestamps pr√©cis
- [ ] AC5: Source file + line number
- [ ] AC6: Config enable/disable capture

**Technical Notes:**
- Rod d√©j√† supporte console events
- Ajouter ConsoleLogs []ConsoleLog dans Step
- Render dans HTML template

**Dependencies:** Rod browser, HTML reporter

**Success Metrics:**
- 100% console events captur√©s
- Overhead < 5% performance

---

#### FR-008: Network Request Logging
**Priority:** P1 - High  
**Effort:** Faible (2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux logger toutes requ√™tes HTTP/GraphQL pour debug API failures.

**Acceptance Criteria:**
- [ ] AC1: Log request: method, URL, headers, body
- [ ] AC2: Log response: status, headers, body, timing
- [ ] AC3: Affichage dans reports
- [ ] AC4: Filtrage par status code
- [ ] AC5: Highlight failed requests
- [ ] AC6: Export HAR format (optional)

**Technical Notes:**
- Wrapper HTTP client existant
- Interceptor pattern
- Store dans Step context
- Render dans HTML report

**Dependencies:** HTTP client, Reporter

**Success Metrics:**
- Toutes requ√™tes logg√©es
- Performance overhead < 2%

---

#### FR-009: WebSocket Testing
**Priority:** P1 - High  
**Effort:** Faible (2-3 jours)  
**Impact:** Moyen-√âlev√©  

**User Story:**
En tant que QA Engineer, je veux tester WebSocket connections pour valider temps-r√©el features (chat, notifications).

**Acceptance Criteria:**
- [ ] AC1: Step: `I connect to WebSocket "ws://..."`
- [ ] AC2: Step: `I send WebSocket message "..."`
- [ ] AC3: Step: `I should receive WebSocket message containing "..."`
- [ ] AC4: Support JSON messages
- [ ] AC5: Timeout configurable
- [ ] AC6: Close connection step
- [ ] AC7: Multiple connections simultan√©es

**Technical Notes:**
- Library: `github.com/gorilla/websocket`
- Nouveaux steps dans `backend/websocket/`
- Context storage pour connections
- Cleanup dans AfterScenario

**Dependencies:** Backend step pattern

**Success Metrics:**
- Support ws:// et wss://
- Reconnection automatique

---

#### FR-010: Test Skip/Pending Support
**Priority:** P1 - High  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux marquer tests comme @skip, @pending, @wip pour control ex√©cution.

**Acceptance Criteria:**
- [ ] AC1: Tag @skip ‚Üí test skipped
- [ ] AC2: Tag @pending ‚Üí test executed mais √©chec OK
- [ ] AC3: Tag @wip ‚Üí work in progress filter
- [ ] AC4: CLI: `--skip-pending` flag
- [ ] AC5: Reports montrent status skip/pending
- [ ] AC6: M√©triques s√©par√©es

**Technical Notes:**
- Godog supporte skip nativement
- √âtendre tag filtering
- Ajouter status Pending dans Report
- Mapping tags ‚Üí behavior

**Dependencies:** Tag system existant

**Success Metrics:**
- Tags fonctionnent 100% cas
- Reports clairs skip vs failed

---

### üéØ PHASE 2: High-Value Features (Sprint 3-4, 4 semaines)

#### FR-011: Cookie Management Enhanced
**Priority:** P2 - Medium  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux g√©rer cookies (set, get, delete) pour tester session et auth.

**Acceptance Criteria:**
- [ ] AC1: Step: `I set cookie "name" to "value"`
- [ ] AC2: Step: `the cookie "name" should be "value"`
- [ ] AC3: Step: `I delete cookie "name"`
- [ ] AC4: Step: `I clear all cookies`
- [ ] AC5: Support domain, path, expiry
- [ ] AC6: Cookie storage dans variables

**Technical Notes:**
- Rod supporte cookies nativement
- Nouveaux steps `frontend/cookies/`
- Validation cookie attributes

**Dependencies:** Browser interface

**Success Metrics:**
- CRUD cookies complet
- Support all cookie attributes

---

#### FR-012: Local Storage / Session Storage
**Priority:** P2 - Medium  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux manipuler localStorage/sessionStorage pour tester client-side state.

**Acceptance Criteria:**
- [ ] AC1: Step: `I set localStorage "key" to "value"`
- [ ] AC2: Step: `localStorage "key" should be "value"`
- [ ] AC3: Step: `I clear localStorage`
- [ ] AC4: Support sessionStorage
- [ ] AC5: Support JSON values
- [ ] AC6: Storage variables cross-step

**Technical Notes:**
- Rod execute JavaScript nativement
- Steps: `page.Eval("localStorage.setItem...")`
- Helper functions pour serialize/deserialize

**Dependencies:** Browser JavaScript execution

**Success Metrics:**
- CRUD storage complet
- Support types complexes (JSON)

---

#### FR-013: File Download Validation
**Priority:** P2 - Medium  
**Effort:** Faible (2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux valider fichiers t√©l√©charg√©s (nom, taille, contenu).

**Acceptance Criteria:**
- [ ] AC1: Step: `I download file from "button"`
- [ ] AC2: Step: `the downloaded file name should be "report.pdf"`
- [ ] AC3: Step: `the downloaded file size should be > 1MB`
- [ ] AC4: Step: `the downloaded file should contain "text"`
- [ ] AC5: Support PDF, CSV, Excel, images
- [ ] AC6: Cleanup files apr√®s test

**Technical Notes:**
- Rod download interceptor
- File validation helpers
- Temp directory pour downloads
- Cleanup dans AfterScenario

**Dependencies:** File system utils

**Success Metrics:**
- Support formats communs
- Cleanup automatique

---

#### FR-014: PDF Testing Support
**Priority:** P2 - Medium  
**Effort:** Faible (2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux extraire et valider contenu PDF.

**Acceptance Criteria:**
- [ ] AC1: Step: `the PDF "file" should contain "text"`
- [ ] AC2: Extract PDF pages count
- [ ] AC3: Extract PDF metadata
- [ ] AC4: Validate PDF structure
- [ ] AC5: Compare PDF content
- [ ] AC6: Support encrypted PDFs

**Technical Notes:**
- Library: `github.com/ledongthuc/pdf`
- PDF parser helper
- Text extraction utilities

**Dependencies:** File download validation

**Success Metrics:**
- Extract text 95%+ accuracy
- Support PDF 1.4-1.7

---

#### FR-015: iFrame Support
**Priority:** P2 - Medium  
**Effort:** Faible (1-2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux interagir avec √©l√©ments dans iframes.

**Acceptance Criteria:**
- [ ] AC1: Step: `I switch to iframe "name"`
- [ ] AC2: Step: `I switch to iframe by selector "css"`
- [ ] AC3: Step: `I switch to parent frame`
- [ ] AC4: Auto-detect iframe context
- [ ] AC5: Nested iframes support
- [ ] AC6: Element search dans iframe

**Technical Notes:**
- Rod supporte frames
- Context switching dans scenario
- Frame stack pour nested

**Dependencies:** Browser context

**Success Metrics:**
- Support nested iframes (3+ levels)
- Auto-switch fluide

---

#### FR-016: Shadow DOM Support
**Priority:** P2 - Medium  
**Effort:** Faible (1-2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux s√©lectionner √©l√©ments dans Shadow DOM (web components).

**Acceptance Criteria:**
- [ ] AC1: Selector: `shadow::#element`
- [ ] AC2: Step: `I click shadow element "selector"`
- [ ] AC3: Nested shadow roots support
- [ ] AC4: Auto-detect shadow DOM
- [ ] AC5: Fallback si pas shadow
- [ ] AC6: Documentation selectors

**Technical Notes:**
- Rod supporte shadow root
- Extend selector strategy
- ShadowRoot traversal

**Dependencies:** Selector engine

**Success Metrics:**
- Support web components communs
- Performance selector acceptable

---

#### FR-017: Multi-Tab Enhanced
**Priority:** P2 - Medium  
**Effort:** Faible (1-2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux g√©rer multiples tabs (switch, close) pour tester popup flows.

**Acceptance Criteria:**
- [ ] AC1: Step: `I switch to tab "index"`
- [ ] AC2: Step: `I switch to tab with title "..."`
- [ ] AC3: Step: `I close current tab`
- [ ] AC4: Step: `I close all tabs except main`
- [ ] AC5: List tabs step
- [ ] AC6: Wait for new tab step

**Technical Notes:**
- Rod g√®re multi-tabs
- Tab tracking dans context
- Cleanup tabs AfterScenario

**Dependencies:** Browser page management

**Success Metrics:**
- Support 10+ tabs simultan√©s
- Tab switching < 100ms

---

#### FR-018: Network Throttling
**Priority:** P2 - Medium  
**Effort:** Faible (1 jour)  
**Impact:** Faible-Moyen  

**User Story:**
En tant que QA Engineer, je veux simuler connexions lentes (3G, 4G) pour tester performance.

**Acceptance Criteria:**
- [ ] AC1: Step: `I set network to "3G"`
- [ ] AC2: Presets: Fast3G, Slow3G, 4G, Offline
- [ ] AC3: Custom: download/upload speed
- [ ] AC4: Latency simulation
- [ ] AC5: Reset network step
- [ ] AC6: Config network profile

**Technical Notes:**
- Rod/CDP network conditions
- Network profiles presets
- Apply globally ou par test

**Dependencies:** Browser CDP

**Success Metrics:**
- Simulation pr√©cise (¬±10%)
- Presets communs disponibles

---

#### FR-019: Geolocation Mocking
**Priority:** P2 - Medium  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Faible  

**User Story:**
En tant que Developer, je veux mock geolocation pour tester location-based features.

**Acceptance Criteria:**
- [ ] AC1: Step: `I set geolocation to "lat, lng"`
- [ ] AC2: Presets: Paris, NYC, Tokyo, etc.
- [ ] AC3: Accuracy parameter
- [ ] AC4: Reset geolocation step
- [ ] AC5: Deny geolocation permission

**Technical Notes:**
- Rod/CDP geolocation override
- Preset coordinates helper
- Permission API

**Dependencies:** Browser API wrapper

**Success Metrics:**
- Coordinates pr√©cises
- 10+ presets cities

---

#### FR-020: Basic Accessibility Checks
**Priority:** P2 - Medium  
**Effort:** Moyen (3-4 jours)  
**Impact:** √âlev√©  

**User Story:**
En tant que QA Engineer, je veux valider accessibilit√© basique (WCAG AA) automatiquement.

**Acceptance Criteria:**
- [ ] AC1: Step: `the page should be accessible`
- [ ] AC2: Check: alt text images
- [ ] AC3: Check: form labels
- [ ] AC4: Check: color contrast
- [ ] AC5: Check: ARIA attributes
- [ ] AC6: Report violations d√©taill√©
- [ ] AC7: Config severity levels

**Technical Notes:**
- Library: axe-core via JavaScript
- Inject axe-core script
- Parse violations
- Report accessible format

**Dependencies:** Browser JavaScript execution

**Success Metrics:**
- D√©tection 80%+ violations WCAG AA
- False positives < 5%

---

### üéØ PHASE 3: Differentiators (Sprint 5-6, 4 semaines)

#### FR-021: Visual Screenshot Comparison
**Priority:** P3 - Nice to Have  
**Effort:** Moyen (4-5 jours)  
**Impact:** Tr√®s √©lev√©  

**User Story:**
En tant que QA Engineer, je veux comparer screenshots baseline vs current pour d√©tecter r√©gression visuelle.

**Acceptance Criteria:**
- [ ] AC1: Step: `I save screenshot baseline "name"`
- [ ] AC2: Step: `the page should match baseline "name"`
- [ ] AC3: Diff percentage configurable (5% tolerance)
- [ ] AC4: Highlight differences dans rapport
- [ ] AC5: Update baseline step
- [ ] AC6: Ignore regions (dynamic content)
- [ ] AC7: Responsive screenshots (multiple sizes)

**Technical Notes:**
- Library: `golang.org/x/image` (d√©j√† pr√©sent)
- Pixel diff algorithm
- Baseline storage: `baselines/`
- Diff image generation

**Dependencies:** Screenshot system existant

**Success Metrics:**
- D√©tection changements 1 pixel
- Comparison < 500ms per image
- Ignore regions efficace

---

#### FR-022: GraphQL Schema Validation & Introspection
**Priority:** P3 - Nice to Have  
**Effort:** Faible (2-3 jours)  
**Impact:** Moyen-√âlev√©  

**User Story:**
En tant que Developer, je veux valider schema GraphQL et d√©tecter breaking changes.

**Acceptance Criteria:**
- [ ] AC1: Step: `the GraphQL schema should be valid`
- [ ] AC2: Step: `the schema should have type "User"`
- [ ] AC3: Step: `the schema should have field "User.email"`
- [ ] AC4: Introspection query automatique
- [ ] AC5: Schema diff (baseline vs current)
- [ ] AC6: Breaking changes detection
- [ ] AC7: Schema export SDL format

**Technical Notes:**
- Introspection query standard
- Schema parser GraphQL
- Diff algorithm
- Breaking changes rules

**Dependencies:** GraphQL client existant

**Success Metrics:**
- D√©tection 100% breaking changes
- Introspection < 1s

---

#### FR-023: API Contract Testing (OpenAPI/Swagger)
**Priority:** P3 - Nice to Have  
**Effort:** Moyen (3-4 jours)  
**Impact:** √âlev√©  

**User Story:**
En tant que API Developer, je veux valider responses contre OpenAPI spec pour contract testing.

**Acceptance Criteria:**
- [ ] AC1: Load OpenAPI spec from file/URL
- [ ] AC2: Step: `the response should match OpenAPI spec`
- [ ] AC3: Validate: schema, types, required fields
- [ ] AC4: Validate: status codes allowed
- [ ] AC5: Validate: headers spec
- [ ] AC6: Report violations d√©taill√©
- [ ] AC7: Support OpenAPI 3.0+

**Technical Notes:**
- Library: `github.com/getkin/kin-openapi`
- Spec loader et parser
- Response validator
- Error reporting d√©taill√©

**Dependencies:** REST API testing

**Success Metrics:**
- Support OpenAPI 3.0, 3.1
- Validation compl√®te spec

---

#### FR-024: Database Snapshot & Rollback
**Priority:** P3 - Nice to Have  
**Effort:** Moyen (3-4 jours)  
**Impact:** Moyen  

**User Story:**
En tant que Developer, je veux snapshot DB avant test et rollback apr√®s pour isolation donn√©es.

**Acceptance Criteria:**
- [ ] AC1: @BeforeScenario: auto snapshot DB
- [ ] AC2: @AfterScenario: auto rollback
- [ ] AC3: Support PostgreSQL, MySQL, SQLite
- [ ] AC4: Config: DB connection string
- [ ] AC5: Manual snapshot step
- [ ] AC6: Selective tables snapshot
- [ ] AC7: Performance optimisations (transactions)

**Technical Notes:**
- SQL drivers Go standard
- Transaction wrapper
- Savepoint for nested
- Connection pool management

**Dependencies:** Hooks system

**Success Metrics:**
- Snapshot/rollback < 1s (small DB)
- Isolation 100% garantie

---

#### FR-025: API Response Time Assertions
**Priority:** P3 - Nice to Have  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Moyen  

**User Story:**
En tant que Performance Engineer, je veux assert response time API pour SLA.

**Acceptance Criteria:**
- [ ] AC1: Step: `the response time should be < 200ms`
- [ ] AC2: Step: `the response time should be between 100-500ms`
- [ ] AC3: Percentile assertions: p95 < 1s
- [ ] AC4: Store response times variables
- [ ] AC5: Aggregate metrics scenario
- [ ] AC6: Report slow requests

**Technical Notes:**
- Timer d√©j√† pr√©sent
- Assertion helpers
- Metrics aggregation

**Dependencies:** Performance metrics

**Success Metrics:**
- Timing pr√©cision ¬±5ms
- Percentile calculations corrects

---

#### FR-026: Email Testing (SMTP/IMAP)
**Priority:** P3 - Nice to Have  
**Effort:** Moyen (3 jours)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux v√©rifier emails re√ßus pour tester notifications/registration flows.

**Acceptance Criteria:**
- [ ] AC1: Step: `I should receive email with subject "..."`
- [ ] AC2: Step: `the email body should contain "..."`
- [ ] AC3: Step: `I click link in email`
- [ ] AC4: Support HTML/text emails
- [ ] AC5: Timeout configurable
- [ ] AC6: Clear inbox step
- [ ] AC7: Multiple IMAP accounts

**Technical Notes:**
- Library: `github.com/emersion/go-imap`
- IMAP connection pool
- Email parser HTML/text
- Link extraction

**Dependencies:** Backend pattern

**Success Metrics:**
- Latency email < 5s
- Parse HTML emails 100%

---

#### FR-027: Keyboard Shortcuts Testing
**Priority:** P3 - Nice to Have  
**Effort:** Faible (1-2 jours)  
**Impact:** Faible-Moyen  

**User Story:**
En tant que QA Engineer, je veux tester keyboard shortcuts (Ctrl+S, Alt+Tab).

**Acceptance Criteria:**
- [ ] AC1: Step: `I press "Ctrl+S"`
- [ ] AC2: Step: `I press keys "Cmd+Shift+P"` (Mac)
- [ ] AC3: Support modifiers: Ctrl, Alt, Shift, Cmd
- [ ] AC4: Support special keys: Enter, Tab, Esc
- [ ] AC5: Key combinations
- [ ] AC6: OS-agnostic (Mac/Windows/Linux)

**Technical Notes:**
- Rod keyboard API
- Key mapping helper
- OS detection

**Dependencies:** Keyboard actions existant

**Success Metrics:**
- Support 50+ key combinations
- Cross-platform compatible

---

#### FR-028: Component/Widget Library Testing
**Priority:** P3 - Nice to Have  
**Effort:** Faible (2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que Frontend Developer, je veux pre-built steps pour Material-UI, Bootstrap, Ant Design.

**Acceptance Criteria:**
- [ ] AC1: Steps Material-UI: Dialog, Select, DatePicker
- [ ] AC2: Steps Bootstrap: Modal, Dropdown, Tab
- [ ] AC3: Steps Ant Design: Table, Form, Menu
- [ ] AC4: Auto-detect framework
- [ ] AC5: Selector patterns optimis√©s
- [ ] AC6: Documentation par framework

**Technical Notes:**
- Selector libraries per framework
- Pattern detection
- Helper functions r√©utilisables

**Dependencies:** Element detection

**Success Metrics:**
- Support 3+ UI frameworks
- Patterns optimis√©s 95% success

---

#### FR-029: Test Execution Time Budget
**Priority:** P3 - Nice to Have  
**Effort:** Tr√®s faible (1 jour)  
**Impact:** Faible-Moyen  

**User Story:**
En tant que Developer, je veux enforcer time budget (max 5min) pour emp√™cher tests lents.

**Acceptance Criteria:**
- [ ] AC1: Config: `max_scenario_duration: 300s`
- [ ] AC2: Fail test si > budget
- [ ] AC3: Warning si > 80% budget
- [ ] AC4: Per-scenario budget tag
- [ ] AC5: Report budget violations
- [ ] AC6: CI/CD integration

**Technical Notes:**
- Timer scenario existant
- Timeout enforcement
- Warnings progressive

**Dependencies:** Performance metrics

**Success Metrics:**
- Enforcement pr√©cis ¬±1s
- CI/CD integration facile

---

#### FR-030: Smart Wait Strategies
**Priority:** P3 - Nice to Have  
**Effort:** Faible (2 jours)  
**Impact:** Moyen  

**User Story:**
En tant que QA Engineer, je veux intelligent waits (network idle, animations done) pour r√©duire flakiness.

**Acceptance Criteria:**
- [ ] AC1: Step: `I wait for network idle`
- [ ] AC2: Step: `I wait for animations to complete`
- [ ] AC3: Step: `I wait for CPU idle`
- [ ] AC4: Auto-wait configurable
- [ ] AC5: Timeout per wait type
- [ ] AC6: Fallback si wait √©choue

**Technical Notes:**
- Rod wait strategies API
- Network idle detection
- CSS animations detection
- CPU idle monitoring

**Dependencies:** Wait system existant

**Success Metrics:**
- Reduce flakiness 50%+
- Wait overhead acceptable

---

## üéÅ Bonus Features (< 1 jour each, Sprint 7)

#### FR-031 √† FR-040: Quick Polish Features

| ID | Feature | Effort | Impact |
|---|---------|--------|--------|
| FR-031 | Color-coded Test Results Enhanced | 4h | Faible |
| FR-032 | Progress Bar CLI | 4h | Faible |
| FR-033 | Emoji Support in Reports | 2h | Faible |
| FR-034 | Auto-retry Failed Tests | 6h | Moyen |
| FR-035 | Test Duration Warnings | 3h | Faible |
| FR-036 | Config Validation CLI | 6h | Moyen |
| FR-037 | Step Definitions List CLI | 4h | Moyen |
| FR-038 | Dry Run Mode | 6h | Moyen |
| FR-039 | Watch Mode (re-run on changes) | 1j | Moyen |
| FR-040 | Interactive Mode (choose tests) | 1j | Moyen |

**Total Bonus Effort:** ~5 jours

---

## üìà Success Criteria & Metrics

### Product Metrics

#### Adoption
- **Installation Growth:** 15% MoM
- **Active Users:** 5,000+ monthly
- **Enterprise Adoption:** 100+ companies
- **Community Size:** 5,000+ GitHub stars

#### Engagement
- **Test Execution:** 100K+ tests/day
- **Report Generation:** 10K+ reports/day
- **Feature Usage:** 70%+ use Quick Wins features
- **Retention:** 40% Day-30 retention

#### Quality
- **Crash Rate:** < 0.1%
- **Bug Reports:** < 10/semaine
- **Performance:** Maintain 5x speed advantage
- **Satisfaction:** NPS > 50

### Technical Metrics

#### Performance
- **Test Speed:** 5x plus rapide que Selenium
- **Setup Time:** < 10 minutes
- **Report Generation:** < 2s
- **Resource Usage:** < 500MB RAM

#### Reliability
- **Flaky Tests:** < 2%
- **Uptime:** 99.9%
- **Test Stability:** 98%+ reproducible
- **Error Rate:** < 1%

#### Coverage
- **Code Coverage:** 80%+
- **Feature Coverage:** 90%+ PRD features
- **Platform Support:** 3+ OS (Mac, Linux, Windows)
- **Browser Support:** Chrome (V1), +Firefox/Safari (V2)

---

## üóìÔ∏è Roadmap & Timeline

### V1.0 Enterprise Edition - Q2 2026 (7 semaines)

#### Sprint 1 (Semaines 1-2): Must-Have Core
- FR-001: Allure Reporting ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- FR-002: Cucumber JSON Export ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- FR-003: Env Vars Override ‚≠ê‚≠ê‚≠ê‚≠ê
- FR-004: Test Data Faker ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- FR-005: Performance Metrics ‚≠ê‚≠ê‚≠ê‚≠ê

**Deliverable:** Professional reporting + data generation

#### Sprint 2 (Semaines 3-4): High-Value Features
- FR-006: CSV Data-Driven ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- FR-007: Console Logs Capture ‚≠ê‚≠ê‚≠ê‚≠ê
- FR-008: Network Request Logging ‚≠ê‚≠ê‚≠ê‚≠ê
- FR-009: WebSocket Testing ‚≠ê‚≠ê‚≠ê‚≠ê
- FR-010: Test Skip/Pending ‚≠ê‚≠ê‚≠ê‚≠ê

**Deliverable:** Enterprise debugging capabilities

#### Sprint 3 (Semaines 5-6): Differentiators
- FR-021: Visual Screenshot Comparison ‚≠ê‚≠ê‚≠ê‚≠ê
- FR-022: GraphQL Schema Validation ‚≠ê‚≠ê‚≠ê‚≠ê
- FR-011 √† FR-020: Quick additions (10 features)

**Deliverable:** Market differentiation features

#### Sprint 4 (Semaine 7): Polish & Launch
- FR-031 √† FR-040: Bonus features (10 features)
- Documentation compl√®te
- Examples & tutorials
- Beta testing
- Launch preparation

**Deliverable:** V1.0 Production-ready

### V1.1 - Q3 2026 (Iteration rapide)
- Bug fixes V1.0
- Performance optimizations
- UX improvements
- Community feedback

### V2.0 - Q4 2026 (Enterprise Advanced)
- JUnit XML Reporting (FR-041)
- Retry Mechanism & Flaky Detection (FR-042)
- Video Recording (FR-043)
- Cross-Browser Support Firefox/Safari (FR-044)
- Mobile Testing (Appium) (FR-045)

### V3.0 - 2027 (Full Enterprise)
- Security & Compliance (RBAC, Audit, Secrets)
- Cloud Integration (BrowserStack, Sauce Labs)
- AI Test Generation
- Distributed Execution
- Multi-tenancy

---

## üí∞ Business Model (Optional)

### Open Source Core (MIT License)
- Gratuit pour tous
- Community support
- Basic features

### Enterprise Edition (Paid)
**Pricing:** $5K - $50K/an
- Advanced features (Security, Compliance)
- Priority support
- SLA garanties
- Training & certification
- Custom integrations

### Cloud Hosting (SaaS)
**Pricing:** $500 - $5K/mois
- Hosted infrastructure
- Distributed execution
- Unlimited tests
- Storage & analytics
- API access

### Professional Services
- Consulting: $200-$400/h
- Training: $2K-$10K
- Custom development
- Migration services

---

## üéì Go-to-Market Strategy

### Launch Plan

#### Phase 1: Soft Launch (Semaine 1-2)
- Beta testers (50 early adopters)
- Collect feedback
- Fix critical bugs
- Polish UX

#### Phase 2: Public Launch (Semaine 3)
- Press release
- Blog post series
- Social media campaign
- Product Hunt launch
- Hacker News post

#### Phase 3: Growth (Semaine 4-12)
- Content marketing (tutorials, case studies)
- Conference talks
- Webinars
- Partner integrations
- Community building

### Marketing Channels

1. **Developer Communities**
   - GitHub
   - Reddit (r/QualityAssurance, r/golang)
   - Dev.to
   - Hacker News

2. **Content Marketing**
   - Blog posts techniques
   - Video tutorials
   - Comparison guides
   - Case studies

3. **Partnerships**
   - CI/CD platforms (Jenkins, GitLab)
   - Cloud providers (AWS, Azure, GCP)
   - Testing tools (Allure, ReportPortal)

4. **Events**
   - QA conferences
   - Go conferences
   - DevOps meetups
   - Webinars

---

## üîß Technical Considerations

### Architecture Impact

#### Minimal Changes Required
‚úÖ Clean Architecture d√©j√† en place  
‚úÖ Interface-based design permet extensions  
‚úÖ Reporter pattern supporte nouveaux formats  
‚úÖ Step builder syst√®me extensible  

#### New Components

1. **Reporters Package**
   - AllureReporter
   - CucumberJSONReporter
   - JUnitXMLReporter (V2)

2. **Data Package**
   - Faker generator
   - CSV/Excel parser
   - Data provider interface

3. **Testing Package**
   - WebSocket client
   - Email client (IMAP)
   - PDF parser

4. **Visual Package**
   - Screenshot comparison
   - Diff algorithm
   - Baseline storage

### Performance Considerations

**Target:**
- Overhead features < 10% temps ex√©cution
- Memory usage < 100MB additionnel
- Startup time < 1s

**Optimizations:**
- Lazy loading features
- Caching strategies
- Parallel processing
- Resource pooling

### Backward Compatibility

**Guarantee:**
- V1.x compatible avec V0.x configs
- Migration guide automatique
- Deprecation warnings (6 mois)
- Legacy mode support

### Security Considerations

**V1.0:**
- Input validation
- Sanitization outputs
- Secure defaults
- Dependency scanning

**V2.0+ (Enterprise):**
- Authentication/Authorization
- Encryption at rest/transit
- Audit logging
- Compliance (SOC2, GDPR)

---

## üìö Documentation Requirements

### User Documentation

1. **Getting Started**
   - Installation (5 min)
   - Quick start tutorial
   - First test in 10 min

2. **Feature Guides**
   - Allure reporting setup
   - Data-driven testing
   - Visual regression
   - GraphQL testing advanced

3. **Step Library**
   - All 200+ steps documented
   - Examples per step
   - Best practices

4. **API Reference**
   - Go package docs
   - Plugin development
   - Custom reporters

### Developer Documentation

1. **Architecture Guide**
   - System design
   - Component interactions
   - Extension points

2. **Contributing Guide**
   - Code standards
   - PR process
   - Testing requirements

3. **Plugin Development**
   - Step definition creation
   - Custom reporters
   - Browser drivers

---

## üéØ Conclusion

### Why This Will Succeed

1. **Clear Market Gap:** Pas de framework BDD Go enterprise-ready
2. **Technical Superiority:** Performance Go 5-10x meilleure
3. **Developer Experience:** Setup simple, debug facile
4. **Realistic Scope:** V1 en 7 semaines avec Quick Wins
5. **Community First:** Open-source avec chemin enterprise

### Investment Required

**Development:** 7 semaines √ó 2 d√©veloppeurs = 14 semaines-dev  
**QA/Testing:** 2 semaines  
**Documentation:** 2 semaines  
**Marketing/Launch:** 2 semaines  

**Total:** ~20 semaines-personne

### Expected ROI

**Year 1:**
- 10,000 installations
- 500 enterprise users ($2.5M ARR si $5K/an)
- Strong community (5K+ stars)
- Market positioning √©tabli

**Year 2:**
- 50,000 installations
- 2,000 enterprise users ($10M ARR)
- Cloud SaaS launch
- Industry recognition

---

## ‚úÖ Next Steps

### Immediate Actions (Semaine 1)

1. **Validation PRD**
   - Review avec stakeholders
   - Feedback utilisateurs beta
   - Ajustements priorit√©s

2. **Team Setup**
   - Recruter d√©veloppeurs Go
   - Setup environnement dev
   - CI/CD pipeline

3. **Sprint Planning**
   - D√©tailler Sprint 1 tasks
   - Cr√©er epics & stories
   - Assign team members

4. **Architecture Review**
   - Valider design features
   - Identify technical risks
   - Proof of concepts

### Sign-off Required

- [ ] Product Manager approval
- [ ] Architect approval
- [ ] Engineering lead approval
- [ ] Stakeholders buy-in

---

**Document prepared by:** Product Manager (John)  
**Date:** 2026-01-22  
**Version:** 1.0 - Ready for Review  
**Next Review:** Sprint Planning Meeting
